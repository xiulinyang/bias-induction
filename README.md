# human-like-bias

# Generalization
| **Paper**                                                    | **Venue** | **Year** | **Code**                                               | 
| ------------------------------------------------------------ | --------- | -------- | ------------------------------------------------------------ |
| [Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations](https://aclanthology.org/2024.emnlp-main.645/) | EMNLP | 2024| [code](https://github.com/namednil/step)|
|[SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation](https://aclanthology.org/2024.acl-long.355/) | ACL| 2024 | [code](https://github.com/namednil/sip)|
|[Injecting structural hints: Using language models to study inductive biases in language learning](https://aclanthology.org/2023.findings-emnlp.563/) | EMNLP findings | 2023| [code](https://github.com/toizzy/injecting-structural-hints)|
|[Does Vision Accelerate Hierarchical Generalization in Neural Language Learners?](https://aclanthology.org/2025.coling-main.127/)|COLING| 2025|NA|
|[Distilling symbolic priors for concept learning into neural networks](https://arxiv.org/abs/2402.07035)| Preprint | 2024| NA|

# Psychometric
| **Paper**                                                    | **Venue** | **Year** | **Code**                                               | 
| ------------------------------------------------------------ | --------- | -------- | ------------------------------------------------------------ |
[Language Models Grow Less Humanlike beyond Phase Transition](https://arxiv.org/abs/2502.18802)|Preprint| 2025| NA|
|[Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs](https://arxiv.org/abs/2309.07311)|ICLR|2024| NA|
# Training


# Inference
